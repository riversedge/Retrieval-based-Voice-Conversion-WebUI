import os

import torch
from fairseq import checkpoint_utils
from fairseq.data.dictionary import Dictionary

from infer.lib.torch_load_compat import torch_load_compat


def get_index_path_from_model(sid):
    return next(
        (
            f
            for f in [
                os.path.join(root, name)
                for root, _, files in os.walk(os.getenv("index_root"), topdown=False)
                for name in files
                if name.endswith(".index") and "trained" not in name
            ]
            if sid.split(".")[0] in f
        ),
        "",
    )

def load_hubert(config):
    try:
        torch.serialization.add_safe_globals([Dictionary])
    except Exception:
        pass
    original_torch_load = torch.load

    def _torch_load(*args, **kwargs):
        kwargs.setdefault("weights_only_default", False)
        return torch_load_compat(*args, load_fn=original_torch_load, **kwargs)

    torch.load = _torch_load
    try:
        models, _, _ = checkpoint_utils.load_model_ensemble_and_task(
            ["assets/hubert/hubert_base.pt"],
            suffix="",
        )
        hubert_model = models[0]
        hubert_model = hubert_model.to(config.device)
        if config.is_half:
            hubert_model = hubert_model.half()
        else:
            hubert_model = hubert_model.float()
        return hubert_model.eval()
    finally:
        torch.load = original_torch_load
